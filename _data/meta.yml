index:
  welcome_message: >
    Welcome! I'm building interpretable & explainable AI.

  personal_photo: "/assets/profile.jpeg"
  image_credit: >
    This is me. :)

  news_highlight_color: 'is-info'

  personal_description: >
    <p>
      Hello! Iâ€™m <strong>Akshat Dubey</strong>, a <strong>Research Associate</strong> at the <a href="https://www.rki.de" target="_blank">Robert Koch Institute</a> and a <strong>PhD candidate</strong> at <a href="https://www.fu-berlin.de" target="_blank">Freie UniversitÃ¤t Berlin</a>, working under the supervision of <strong>Dr.â€¯habil.â€¯Georges Hattab</strong>.
    </p>

    <p>
      My research lies at the intersection of <strong>Explainable Artificial Intelligence (XAI)</strong>, NLP, and human-centered AI. I focus on building interpretable, transparent, and efficient ML systems for critical domains like healthcare. My work draws from ensemble tree ML models, probabilistic modeling, optimization, statistics, and LLMs, with current themes including:
    </p>

    <ul style="list-style: none; padding-left: 0;">
      <li>ğŸ” <strong>Uncertainty Quantification in XAI</strong>  
        <br><em>Designing principled methods to estimate and communicate explanation confidenceâ€”especially in high-stakes domains.</em></li><br>

      <li>ğŸ¥ <strong>XAI for Healthcare</strong>  
        <br><em>Embedding explainable and uncertainty-aware models into real-world clinical workflows to support informed decision-making.</em></li><br>

      <li>ğŸ§  <strong>Persona-Adaptable LLM Strategies</strong>  
        <br><em>Tailoring large language models to align with usersâ€™ cognitive styles and mental modelsâ€”enabling intuitive and adaptive interaction.</em></li><br>

      <li>âš–ï¸ <strong>Regulatory-Compliant AI Design</strong>  
        <br><em>Implementing the â€œNested Model for AI Design & Validationâ€ to meet the EU AI Actâ€™s transparency and safety requirements.</em></li><br>

      <li>ğŸ² <strong>Distributed Gaussian Process Learning</strong>  
        <br><em>Developing decentralized, trust-aware GP frameworks for collaborative and privacy-preserving learning.</em></li><br>

      <li>ğŸ§  <strong>LLMs with LoRA/QLoRA & Quantization</strong>  
        <br><em>Enabling efficient, on-device large-model inference using quantized, low-rank-adapted LLMs for constrained environments.</em></li><br>

      <li>ğŸ³ <strong>Reproducible ML via Docker & Orchestration</strong>  
        <br><em>Building automated, scalable pipelines for training, deploying, and monitoring ML models with full reproducibility.</em></li><br>

      <li>ğŸ“ˆ <strong>MILP for Interpretable Graph Design</strong>  
        <br><em>Using mixed-integer linear programming to optimize surrogate graph structures from decision forests for maximum interpretability.</em></li><br>

      <li>ğŸ¤ <strong>Human-in-the-Loop AI: GNNs, NLP, and Visual Analytics</strong>  
        <br><em>Fusing graph learning, language understanding, and interaction design to make AI decisions transparent, explorable, and trustworthy.</em></li>
    </ul>

    <p>
      Outside of research, Iâ€™m a lifelong learner, â€œmath nerd,â€ and â€œalgorithm enthusiastâ€ passionate about systems that empower humans through explainability. I enjoy building bridges between theory and practice.
    </p>

    <p>
      Letâ€™s connect and collaborateâ€”reach out on <a href="https://www.linkedin.com/in/Akshat0007" target="_blank"><strong>LinkedIn</strong></a>.
    </p>

  footnote: >
    <small>
      Site crafted by <a href="https://github.com/dubeyakshat07" target="_blank">Akshat Dubey</a> using <a href="https://jekyllrb.com/" target="_blank">Jekyll</a> and <a href="https://bulma.io/" target="_blank">Bulma</a>.  
      Content licensed under <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a>.
    </small>
